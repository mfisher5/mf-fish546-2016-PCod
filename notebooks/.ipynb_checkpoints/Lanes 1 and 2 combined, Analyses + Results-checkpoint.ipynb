{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanes 1 & 2:\n",
    "## Results of Data Processing + Analyses of Sequencing Data\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This notebook (1) summarizes the results of the sequence data processing pipeline, and (2) goes through popgen analyses. This includes: \n",
    "\n",
    "1. Tracking the number of loci through filtering steps (per individual, in catalog)\n",
    "2. Tracking the number of sequences per individual\n",
    "3. Genotype mismatches between 300ng and 500ng protocols\n",
    "4. Pairwise Fst\n",
    "5. Global Fst\n",
    "6. Population-specific Fis comparisons\n",
    "7. DAPC plot\n",
    "\n",
    "<BR>\n",
    "<BR>\n",
    "<BR>\n",
    "### Tracking the number of sequences through filtering steps\n",
    "\n",
    "**(1)** `process_radtags` : per lane\n",
    "\n",
    "I already have this output from the command line code, found in the Jupyter notebook `Lanes 1 and 2 combined pipeline`. \n",
    "\n",
    "Lane 1: 447269795 retained reads (83.9%)\n",
    "\n",
    "Lane 2: 259598451 retained reads (68.7%)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "**(2)** `process_radtags` : per individual\n",
    "\n",
    "I found this output when creating my cstacks catalog; it can be found in the excel spreadsheet `L1L2_SortedTotalSeqCounts` (link [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/L1L2_SortedTotalSeqCounts.ods)) in my [Analyses](https://github.com/mfisher5/mf-fish546-2016/tree/master/Analyses) folder. \n",
    "![graph](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/N.Reads_byPop_radtags.png?raw=true)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**(2a)** `process_radtags` : comparison 300ng v. 500ng\n",
    "\n",
    "I also found this output when creating my cstacks catalog; it can be found in the excel spreadsheet `L1L2_SortedTotalSeqCounts` (link [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/L1L2_SortedTotalSeqCounts.ods)) in my [Analyses](https://github.com/mfisher5/mf-fish546-2016/tree/master/Analyses) folder. \n",
    "![graph](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/N.Reads_300v500_radtags.png?raw=true)\n",
    "\n",
    "\n",
    "*I noticed that I am missing the sequence count data for several individuals from YS and BOR because I didn't need to know their read depths to create the cstacks catalog; I found those read depths below*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/L1L2stacks_m10\n"
     ]
    }
   ],
   "source": [
    "cd ../../L1L2stacks_m10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/L1L2samplesT142\n"
     ]
    }
   ],
   "source": [
    "cd ../L1L2samplesT142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717981 211440 12.3075 TGCAGGACGCTTTTTCACGTTCTGGTTGGTTGTGGCCTGTTGATGCTAAAGGTGAGCCGCTTAAAGCTACCAGTTATATGGCTGTTGGTTTCTATGTGGCTAAATACGTTAACAAAAAGTCAGATATGGACCTTGCTGCTAA 10009 0.582602\n",
      "2968140 276502 9.31567 TGCAGGACTCATAGTGCTTGCTCACTTTAAGAAATACTAGAACACCACAGCCCCTCATTAGTACAGTGGTCAGTATCCATTGGCCATGCATGAAACCAGGAATGTGAAGATTCTTGGTTTAACTCAGTCCGAACGAAAAGAG 20471 0.689691\n",
      "5769259 531199 9.2074 TGCAGGACTCATAGTGCTTGCTCACTTTAAGAAATACTAGAACACCACAGCCCCTCATTAGTACAGTGGTCAGTATCCATTGGCCATGCATGAAACCAGGAATGTGAAGATTCTTGGTTTAACTCAGTCCGAACGAAAAGAG 32744 0.56756\n"
     ]
    }
   ],
   "source": [
    "!zcat BOR07_01.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'\n",
    "!zcat BOR07_03.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'\n",
    "!zcat BOR07_09.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252448 334984 14.872 TGCAGGACTCATAGTGCTTGCTCACTTTAAGAAATACTAGAACACCACAGCCCCTCATTAGTACAGTGGTCAGTATCCATTGGCCATGCATGAAACCAGGAATGTGAAGATTCTTGGTTTAACTCAGTCCGAACGAAAAGAG 12558 0.557527\n",
      "1311987 210654 16.0561 TGCAGGACTCATAGTGCTTGCTCACTTTAAGAAATACTAGAACACCACAGCCCCTCATTAGTACAGTGGTCAGTATCCATTGGCCATGCATGAAACCAGGAATGTGAAGATTCTTGGTTTAACTCAGTCCGAACGAAAAGAG 7724 0.588725\n",
      "2885627 384075 13.3099 TGCAGGACTCATAGTGCTTGCTCACTTTAAGAAATACTAGAACACCACAGCCCCTCATTAGTACAGTGGTCAGTATCCATTGGCCATGCATGAAACCAGGAATGTGAAGATTCTTGGTTTAACTCAGTCCGAACGAAAAGAG 23370 0.809876\n"
     ]
    }
   ],
   "source": [
    "!zcat YS121315_08.1.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'\n",
    "!zcat YS121315_10.1.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'\n",
    "!zcat YS121315_14.1.fq.gz | awk '((NR-2)%4==0){read=$1;total++;count[read]++}END{for(read in count){if(!max||count[read]>max) {max=count[read];maxRead=read};if(count[read]==1){unique++}};print total,unique,unique*100/total,maxRead,count[maxRead],count[maxRead]*100/total}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**(3)** `final` : per individual\n",
    "\n",
    "*For methods see below.* Results can be found in the `SeqLociCounts_Analysis_L1L2` excel file (Link [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/L1L2_SortedTotalSeqCounts.ods)) in my [Analyses](https://github.com/mfisher5/mf-fish546-2016/tree/master/Analyses) folder. \n",
    "![graph](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/N.Reads_byPop_final.png?raw=true)\n",
    "<br>\n",
    "<br>\n",
    "**(3a)** `final` : comparison 300ng v. 500ng\n",
    "\n",
    "Results can be found in the `SeqLociCounts_Analysis_L1L2` excel file (Link [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/L1L2_SortedTotalSeqCounts.ods)) in my [Analyses](https://github.com/mfisher5/mf-fish546-2016/tree/master/Analyses) folder. \n",
    "![graph](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/N.Reads_300v500_final.png?raw=true)\n",
    "<br>\n",
    "<br>\n",
    "*Methods:*\n",
    "\n",
    "I'm going to calculate the number of reads retained after the final locus filtering step. \n",
    "\n",
    "First: Using the \"Stack Depth\" column (7) in the `.matches.tsv` file for each individual. The 7th column contains the number of reads contained in the sample locus that matched to the catalog.\n",
    "\n",
    "Second: Using the genepop-style .csv file `batch_1_filteredMAF_GOODgenotypes.csv`. I can use this to filter out only the loci in the `.matches.tsv` files that refer to biallelic loci filtered for MAF and missing data. The 3rd column in the `.matches.tsv` file contains the catalog locus ID number. I can use this to filter out only the columns that describe the loci in my FINAL filtered list of loci. \n",
    "\n",
    "<br>\n",
    "I made a python script to find all loci that match the filtered biallelic catalog loci, extract the number in column 7 of each `.matches` file, and then add together the stack depths. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/scripts\n"
     ]
    }
   ],
   "source": [
    "cd ../../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Counts the number of reads in the `.matches` file output from sstacks ####\r\n",
      "\r\n",
      "## MF 12/12/2016\r\n",
      "\r\n",
      "## ARG1 : list of all samples (for paired end, make sure that `.1` is already on the end). I used my population map\r\n",
      "## ARG2 : list of all the final loci (biallelic, filtered for MAF and missing data). I used a text file created from my final .csv file\r\n",
      "\r\n",
      "import sys\r\n",
      "lociFile = open(sys.argv[2], \"r\")\r\n",
      "\r\n",
      "#create list of loci\r\n",
      "lociList = []\r\n",
      "for line in lociFile: \r\n",
      "\ttemplocus = line.strip()\r\n",
      "\tlociList.append(templocus)\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 CountSSTACKS_seqs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ran this in the terminal: \n",
    "python CountSSTACKS_seqs.py PopMap_L1L2stacks.txt batch_1_FinalFilteredLoci.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gave me the file `SSTACKS_SeqCounts_L1L2.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO010715_06.1\r\n",
      "473402\r\n",
      "PO010715_27.1\r\n",
      "579251\r\n",
      "PO010715_28.1\r\n",
      "632368\r\n",
      "PO010715_29.1\r\n",
      "615203\r\n",
      "PO020515_05.1\r\n",
      "739041\r\n"
     ]
    }
   ],
   "source": [
    "!head SSTACKS_SeqCounts_L1L2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I rearranged this in excel, and graphed the comparison (above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking the number of loci through filtering steps\n",
    "\n",
    "\n",
    "I can track the number of loci by opening my catalog files in excel, and counting the number of rows (1 locus = 1 row). I found the following: \n",
    "\n",
    "\n",
    "**CSTACKS** : `181,969`\n",
    "<br>\n",
    "**POPULATIONS** : `21,725`   (11.94% retained from previous step)\n",
    "<br>\n",
    "**UNFILTERED BIALLELIC** : `9,984`    (45.96% retained from previous step)\n",
    "<br>\n",
    "**MAF FILTERED BIALLELIC** : `8,654`    (86.68% retained from previous step)\n",
    "<br>\n",
    "**MAF + MISSING GENOS FILTERED BIALLELIC** : `8,517`    (98.42% retained from previous step)\n",
    "<br>\n",
    "<br>\n",
    "These numbers can also be found in the excel spreadsheet `SeqLociCounts_Analysis_L1L2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genotype Mismatches: 500ng v. 300ng\n",
    "\n",
    "I used the same individuals the test the 300ng protocol as were prepared with the 500ng protocol. So I can compare the genotypes across loci for the same individuals prepared with different protocols, and look for mismatches. \n",
    "\n",
    "I did this, then found the [percent mismatches in genotypes across all loci](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/GenotypeMismatches_300v500.txt). My results summarized as a boxplot: \n",
    "\n",
    "![boxplot](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/GenotypeMismatches_300v500_boxplot.png?raw=true)\n",
    "\n",
    "*Note - this excludes GEO020414_13, as the 500ng sample did not work (will use 300ng in future analyses). The OUTLIER above is GEO020414_15. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise Fst\n",
    "\n",
    "I can find population pairwise FST using my final genepop file, filtered for MAF + missing genotypes. Since I know that my degraded DNA samples (of which all but one were filtered out because they are missing > 50% of their genotypes) are all in the Mukho / Sokcho population, I'm going to run analyses 2 x ; once WITH these samples, and once WITHOUT these samples. \n",
    "\n",
    "I'll be using GENEPOP v...\n",
    "<br>\n",
    "<br>\n",
    "(1) I converted my genepop files from .csv to .genepop using the python script below. Note that you need to have the \"sample\" header. The script first transposes the .csv file (so that sample IDs are in the first column and loci are in the first row), and then writes the content into a genepop file with the structure: \n",
    "\n",
    "---------\n",
    "TITLE\n",
    "<br>\n",
    "Locus1, Locus2, Locus3, etc.\n",
    "<br>\n",
    "Pop\n",
    "<br>\n",
    "pcod1 0101 0101 0101 etc.\n",
    "<br>\n",
    "pcod2 0202 0202 0202 etc.\n",
    "<br>\n",
    "pcod3 0303 0303 0303 etc.\n",
    "<br>\n",
    "Pop\n",
    "<br>\n",
    "pcod4 0404 0404 0404 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hgfs/Pacific cod/DataAnalysis/scripts/UndercallingHets_MB_CW\n"
     ]
    }
   ],
   "source": [
    "cd ../../scripts/UndercallingHets_MB_CW/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### This script converts the FINAL filtered .csv document (corrected genotypes, MAF filtered, low coverage loci filtered, low coverage individuals filtered) into a genepop file format ####\r\n",
      "\r\n",
      "## MF 12/13/2016\r\n",
      "\r\n",
      "## ARG1 : .csv file\r\n",
      "## ARG2 : name of genepop file (must be .gen)\r\n",
      "### Note -- LEAVE the \"sample\" header in the .csv file. Edit the correct title line AND the population indices in the script below. \r\n",
      "#############################################################################################\r\n",
      "\r\n",
      "import sys\r\n"
     ]
    }
   ],
   "source": [
    "!head genepop_conversion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python genepop_conversion_forR.py ../../L1L2stacks_m10/batch_1_filteredMAF_GOODgenotypes_filteredIndivids.csv ../../L1L2stacks_m10/batch_1.filtered_MAF_MissingLoci_Individs.gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then load this genepop file in R using the package `adegenet 2.0.1` and complete the following population genetic analyses, including pairwise Fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAPC Plots\n",
    "\n",
    "I made two types of DAPC plots: one without a clustering algorithm, and one with a clustering algorithm (\"median\"). The R script for creating the DAPC plots can be found [here](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/DAPC_script_Pcod.R). \n",
    "\n",
    "\n",
    "** DAPC WITH ALL POPULATIONS **\n",
    "![dapc_all](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/DAPC_all_noCluster.png?raw=true)\n",
    "\n",
    "![dapc_all_cluster](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/DAPC_all.png?raw=true)\n",
    "\n",
    "**DAPC EXCLUDING YELLOW SEA, BORYEONG** \n",
    "\n",
    "I ran this because the large genetic distance between the Yellow Sea + Boryeong populations and all of the rest of the populations was obscuring the distance between all of the other populations. \n",
    "\n",
    "![dapc](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/DAPC_noYSBOR_noCluster.png?raw=true)\n",
    "\n",
    "![dapc_cluster](https://github.com/mfisher5/mf-fish546-PCod/blob/master/Analyses/DAPC_noYSBOR.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
